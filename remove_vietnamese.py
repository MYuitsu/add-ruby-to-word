#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Script ƒë·ªÉ x√≥a t·∫•t c·∫£ ti·∫øng Vi·ªát kh·ªèi file Word, ch·ªâ gi·ªØ l·∫°i ti·∫øng Nh·∫≠t v√† ti·∫øng Anh
"""

import re
import unicodedata
from docx import Document
from docx.shared import RGBColor
from docx.enum.text import WD_COLOR_INDEX
import os
import sys

def is_vietnamese_char(char):
    """Ki·ªÉm tra xem k√Ω t·ª± c√≥ ph·∫£i l√† k√Ω t·ª± ti·∫øng Vi·ªát kh√¥ng"""
    vietnamese_chars = set([
        '√†', '√°', '·∫£', '√£', '·∫°', 'ƒÉ', '·∫±', '·∫Ø', '·∫≥', '·∫µ', '·∫∑',
        '√¢', '·∫ß', '·∫•', '·∫©', '·∫´', '·∫≠', '√®', '√©', '·∫ª', '·∫Ω', '·∫π',
        '√™', '·ªÅ', '·∫ø', '·ªÉ', '·ªÖ', '·ªá', '√¨', '√≠', '·ªâ', 'ƒ©', '·ªã',
        '√≤', '√≥', '·ªè', '√µ', '·ªç', '√¥', '·ªì', '·ªë', '·ªï', '·ªó', '·ªô',
        '∆°', '·ªù', '·ªõ', '·ªü', '·ª°', '·ª£', '√π', '√∫', '·ªß', '≈©', '·ª•',
        '∆∞', '·ª´', '·ª©', '·ª≠', '·ªØ', '·ª±', '·ª≥', '√Ω', '·ª∑', '·ªπ', '·ªµ',
        'ƒë', '√Ä', '√Å', '·∫¢', '√É', '·∫†', 'ƒÇ', '·∫∞', '·∫Æ', '·∫≤', '·∫¥', '·∫∂',
        '√Ç', '·∫¶', '·∫§', '·∫®', '·∫™', '·∫¨', '√à', '√â', '·∫∫', '·∫º', '·∫∏',
        '√ä', '·ªÄ', '·∫æ', '·ªÇ', '·ªÑ', '·ªÜ', '√å', '√ç', '·ªà', 'ƒ®', '·ªä',
        '√í', '√ì', '·ªé', '√ï', '·ªå', '√î', '·ªí', '·ªê', '·ªî', '·ªñ', '·ªò',
        '∆†', '·ªú', '·ªö', '·ªû', '·ª†', '·ª¢', '√ô', '√ö', '·ª¶', '≈®', '·ª§',
        '∆Ø', '·ª™', '·ª®', '·ª¨', '·ªÆ', '·ª∞', '·ª≤', '√ù', '·ª∂', '·ª∏', '·ª¥',
        'ƒê'
    ])
    return char in vietnamese_chars

def is_japanese_char(char):
    """Ki·ªÉm tra xem k√Ω t·ª± c√≥ ph·∫£i l√† ti·∫øng Nh·∫≠t kh√¥ng"""
    # Hiragana: U+3040-U+309F
    # Katakana: U+30A0-U+30FF
    # CJK Unified Ideographs: U+4E00-U+9FFF (Kanji)
    # CJK Symbols and Punctuation: U+3000-U+303F
    code = ord(char)
    return (0x3040 <= code <= 0x309F or  # Hiragana
            0x30A0 <= code <= 0x30FF or  # Katakana
            0x4E00 <= code <= 0x9FFF or  # Kanji
            0x3000 <= code <= 0x303F)    # CJK punctuation

def is_english_char(char):
    """Ki·ªÉm tra xem k√Ω t·ª± c√≥ ph·∫£i l√† ti·∫øng Anh kh√¥ng"""
    return char.isascii() and (char.isalpha() or char.isdigit() or char in ' .,!?;:()[]{}"-\'')

# Bi·∫øn global ƒë·ªÉ l∆∞u danh s√°ch t·ª´ ti·∫øng Vi·ªát
_vietnamese_words_set = None

def load_vietnamese_words():
    """T·∫£i danh s√°ch t·ª´ ti·∫øng Vi·ªát t·ª´ file vi-DauMoi.txt"""
    global _vietnamese_words_set
    
    if _vietnamese_words_set is not None:
        return _vietnamese_words_set
    
    vietnamese_words = set()
    
    try:
        with open('vi-DauMoi.txt', 'r', encoding='utf-8') as f:
            for line in f:
                word = line.strip()
                if word and len(word) > 0:
                    # Th√™m t·ª´ g·ªëc
                    vietnamese_words.add(word.lower())
                    
                    # N·∫øu t·ª´ c√≥ d·∫•u, th√™m c·∫£ phi√™n b·∫£n kh√¥ng d·∫•u
                    word_no_accent = remove_accents(word)
                    if word_no_accent != word:
                        vietnamese_words.add(word_no_accent.lower())
        
        print(f"‚úÖ ƒê√£ t·∫£i {len(vietnamese_words)} t·ª´ ti·∫øng Vi·ªát t·ª´ file vi-DauMoi.txt")
        
    except FileNotFoundError:
        print("‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y file vi-DauMoi.txt, s·ª≠ d·ª•ng t·ª´ ƒëi·ªÉn hardcode")
        # Fallback v·ªÅ t·ª´ ƒëi·ªÉn hardcode n·∫øu kh√¥ng t√¨m th·∫•y file
        vietnamese_words = get_hardcoded_vietnamese_words()
    except Exception as e:
        print(f"‚ö†Ô∏è  L·ªói khi ƒë·ªçc file vi-DauMoi.txt: {e}, s·ª≠ d·ª•ng t·ª´ ƒëi·ªÉn hardcode")
        vietnamese_words = get_hardcoded_vietnamese_words()
    
    _vietnamese_words_set = vietnamese_words
    return vietnamese_words

def remove_accents(text):
    """Lo·∫°i b·ªè d·∫•u t·ª´ text ti·∫øng Vi·ªát"""
    # B·∫£ng chuy·ªÉn ƒë·ªïi d·∫•u ti·∫øng Vi·ªát
    vietnamese_accent_map = {
        '√†': 'a', '√°': 'a', '·∫£': 'a', '√£': 'a', '·∫°': 'a',
        'ƒÉ': 'a', '·∫±': 'a', '·∫Ø': 'a', '·∫≥': 'a', '·∫µ': 'a', '·∫∑': 'a',
        '√¢': 'a', '·∫ß': 'a', '·∫•': 'a', '·∫©': 'a', '·∫´': 'a', '·∫≠': 'a',
        '√®': 'e', '√©': 'e', '·∫ª': 'e', '·∫Ω': 'e', '·∫π': 'e',
        '√™': 'e', '·ªÅ': 'e', '·∫ø': 'e', '·ªÉ': 'e', '·ªÖ': 'e', '·ªá': 'e',
        '√¨': 'i', '√≠': 'i', '·ªâ': 'i', 'ƒ©': 'i', '·ªã': 'i',
        '√≤': 'o', '√≥': 'o', '·ªè': 'o', '√µ': 'o', '·ªç': 'o',
        '√¥': 'o', '·ªì': 'o', '·ªë': 'o', '·ªï': 'o', '·ªó': 'o', '·ªô': 'o',
        '∆°': 'o', '·ªù': 'o', '·ªõ': 'o', '·ªü': 'o', '·ª°': 'o', '·ª£': 'o',
        '√π': 'u', '√∫': 'u', '·ªß': 'u', '≈©': 'u', '·ª•': 'u',
        '∆∞': 'u', '·ª´': 'u', '·ª©': 'u', '·ª≠': 'u', '·ªØ': 'u', '·ª±': 'u',
        '·ª≥': 'y', '√Ω': 'y', '·ª∑': 'y', '·ªπ': 'y', '·ªµ': 'y',
        'ƒë': 'd',
        '√Ä': 'A', '√Å': 'A', '·∫¢': 'A', '√É': 'A', '·∫†': 'A',
        'ƒÇ': 'A', '·∫∞': 'A', '·∫Æ': 'A', '·∫≤': 'A', '·∫¥': 'A', '·∫∂': 'A',
        '√Ç': 'A', '·∫¶': 'A', '·∫§': 'A', '·∫®': 'A', '·∫™': 'A', '·∫¨': 'A',
        '√à': 'E', '√â': 'E', '·∫∫': 'E', '·∫º': 'E', '·∫∏': 'E',
        '√ä': 'E', '·ªÄ': 'E', '·∫æ': 'E', '·ªÇ': 'E', '·ªÑ': 'E', '·ªÜ': 'E',
        '√å': 'I', '√ç': 'I', '·ªà': 'I', 'ƒ®': 'I', '·ªä': 'I',
        '√í': 'O', '√ì': 'O', '·ªé': 'O', '√ï': 'O', '·ªå': 'O',
        '√î': 'O', '·ªí': 'O', '·ªê': 'O', '·ªî': 'O', '·ªñ': 'O', '·ªò': 'O',
        '∆†': 'O', '·ªú': 'O', '·ªö': 'O', '·ªû': 'O', '·ª†': 'O', '·ª¢': 'O',
        '√ô': 'U', '√ö': 'U', '·ª¶': 'U', '≈®': 'U', '·ª§': 'U',
        '∆Ø': 'U', '·ª™': 'U', '·ª®': 'U', '·ª¨': 'U', '·ªÆ': 'U', '·ª∞': 'U',
        '·ª≤': 'Y', '√ù': 'Y', '·ª∂': 'Y', '·ª∏': 'Y', '·ª¥': 'Y',
        'ƒê': 'D'
    }
    
    result = ''
    for char in text:
        if char in vietnamese_accent_map:
            result += vietnamese_accent_map[char]
        else:
            result += char
    return result

def get_hardcoded_vietnamese_words():
    """Tr·∫£ v·ªÅ t·ª´ ƒëi·ªÉn hardcode l√†m fallback"""
    return {
        # T·ª´ ƒëi·ªÉn hardcode c∆° b·∫£n
        'toi', 'ban', 'no', 'chung', 'ta', 'minh', 'ho', 'may', 'cac', 'nhung', 'moi',
        'nguoi', 'ai', 'gi', 'dau', 'nao', 'sao', 'bao', 'tat', 'ca', 'mang',
        'la', 'co', 'di', 'den', 'lam', 'noi', 'biet', 'thay', 'nghe', 'doc', 'viet', 'hoc',
        'an', 'uong', 'ngu', 'choi', 'xem', 'mua', 'ban', 'cho', 'nhan', 'gui', 'goi',
        'sinh', 'theo', 'van', 'con', 'duoc', 'tim', 'hieu', 'dong', 'chia', 'nhan',
        'dung', 'ngoi', 'nam', 'chay', 'nhay', 'hat', 'khoc', 'cuoi', 'ket',
        'bat', 'dau', 'thuc', 'mo', 'dong', 'cat', 'gan', 'roi', 'bo', 'lay',
        'dem', 'mang', 'dua', 'dieu', 'khien', 'quan', 'ly', 'tri', 'chua',
        'benh', 'viec', 'hoi', 'dap', 'thi', 'tot', 'dep', 'xau', 'cao', 'thap',
        'dai', 'ngan', 'rong', 'hep', 'lon', 'nho', 'nong', 'lanh', 'nhanh', 'cham',
        'khoe', 'om', 'vui', 'buon', 'gioi', 'te', 'trung', 'binh', 'sai', 'dung',
        'chan', 'le', 'cu', 'tre', 'gia', 'khac', 'giong', 'bang', 'hon', 'kem',
        'nhat', 'nhi', 'ba', 'cuoi', 'xa', 'mat', 'am', 'kho', 'uot', 'de',
        'khan', 'den', 'trang', 'do', 'xanh', 'vang', 'tim', 'hong', 'nau',
        'nha', 'truong', 'lop', 'ghe', 'sach', 'but', 'giay', 'ao', 'quan',
        'me', 'bo', 'anh', 'chi', 'em', 'ong', 'ba', 'thay', 'chu',
        'nuoc', 'com', 'pho', 'banh', 'ca', 'thit', 'rau', 'trai', 'gao', 'mi',
        'xe', 'may', 'tau', 'oto', 'duong', 'hang', 'tien', 'tra', 'bieu', 'mau',
        'bai', 'tap', 'de', 'giua', 'phai', 'ben', 'canh', 'tren', 'duoi',
        'trong', 'ngoai', 'truoc', 'sau', 'day', 'kia', 'nay', 'mai', 'hom', 'qua',
        'tuoi', 'nu', 'dan', 'em', 'mot', 'hai', 'bon', 'sau', 'bay', 'tam',
        'chin', 'muoi', 'tram', 'ngan', 'trieu', 'ty', 'le', 'lan', 'phan',
        'ngay', 'thang', 'gio', 'phut', 'giay', 'tuan', 'thoi', 'gian', 'som',
        'muon', 'dem', 'sang', 'chieu', 'toi', 'khuya', 'trua', 'tet', 'hoi',
        'va', 'hoac', 'ma', 'neu', 'vi', 'de', 'tu', 'ben', 'boi', 'nhu',
        'nham', 'vay', 'the', 'khi', 'luc', 'gio', 'tai', 'o', 'ra', 'cach',
        'rat', 'qua', 'cung', 'da', 'dang', 'se', 'chua', 'roi', 'khong',
        'cai', 'chiec', 'chuyen', 'dieu', 'su', 'ay', 'do', 'het', 'xong',
        'co', 'the', 'nen', 'phai', 'can', 'pha', 'i', 'muon', 'thich', 'ghet',
        'so', 'yeu', 'thuong', 'nho', 'quen'
    }

def is_vietnamese_word(word):
    """Ki·ªÉm tra xem t·ª´ c√≥ ph·∫£i l√† ti·∫øng Vi·ªát kh√¥ng (s·ª≠ d·ª•ng t·ª´ ƒëi·ªÉn t·ª´ file)"""
    vietnamese_words = load_vietnamese_words()
    word_lower = word.lower().strip('.,!?;:()[]{}"-\'')
    return word_lower in vietnamese_words

def is_vietnamese_text(text):
    """Ki·ªÉm tra xem ƒëo·∫°n text c√≥ ph·∫£i l√† ti·∫øng Vi·ªát kh√¥ng"""
    if not text or not text.strip():
        return False
    
    # ƒê·∫øm s·ªë k√Ω t·ª± ti·∫øng Vi·ªát (c√≥ d·∫•u)
    vietnamese_char_count = sum(1 for char in text if is_vietnamese_char(char))
    
    # ƒê·∫øm s·ªë t·ª´ ti·∫øng Vi·ªát (kh√¥ng d·∫•u)
    words = text.split()
    vietnamese_word_count = sum(1 for word in words if is_vietnamese_word(word))
    
    total_chars = len([char for char in text if char.isalpha()])
    total_words = len([word for word in words if word.strip('.,!?;:()[]{}"-\'').isalpha()])
    
    if total_chars == 0 and total_words == 0:
        return False
    
    # N·∫øu c√≥ k√Ω t·ª± ti·∫øng Vi·ªát c√≥ d·∫•u
    if total_chars > 0 and vietnamese_char_count / total_chars > 0.1:
        return True
    
    # N·∫øu c√≥ t·ª´ ti·∫øng Vi·ªát kh√¥ng d·∫•u
    if total_words > 0 and vietnamese_word_count / total_words > 0.3:
        return True
    
    return False

def should_remove_vietnamese_word(word):
    """Ki·ªÉm tra xem t·ª´ c√≥ n√™n b·ªã x√≥a (l√† t·ª´ ti·∫øng Vi·ªát) kh√¥ng"""
    # Lo·∫°i b·ªè d·∫•u c√¢u ƒë·ªÉ ki·ªÉm tra t·ª´ thu·∫ßn
    clean_word = word.strip('.,!?;:()[]{}"-\'')
    
    # N·∫øu t·ª´ r·ªóng sau khi lo·∫°i b·ªè d·∫•u c√¢u
    if not clean_word:
        return False
    
    # N·∫øu t·ª´ c√≥ k√Ω t·ª± ti·∫øng Vi·ªát c√≥ d·∫•u th√¨ x√≥a
    if any(is_vietnamese_char(char) for char in clean_word):
        return True
    
    # N·∫øu t·ª´ l√† t·ª´ ti·∫øng Vi·ªát kh√¥ng d·∫•u th√¨ x√≥a
    if is_vietnamese_word(clean_word):
        return True
    
    # Ki·ªÉm tra xem t·ª´ c√≥ ph·∫£i l√† t·ª´ ti·∫øng Vi·ªát vi·∫øt t·∫Øt ho·∫∑c gh√©p kh√¥ng
    # V√≠ d·ª•: "cht", "lng", "qun", "phng", v.v.
    if len(clean_word) >= 2 and clean_word.lower() in load_vietnamese_words():
        return True
    
    # Danh s√°ch c√°c t·ª´ vi·∫øt t·∫Øt ti·∫øng Vi·ªát th∆∞·ªùng g·∫∑p
    vietnamese_abbreviations = {
        'mm', 'cht', 'lng', 'qun', 'phng', 'thn', 'mc', 'sn', 'ph', 'bt', 'ct', 'tr', 'ng', 
        'nh', 'th', 'kh', 'ch', 'vt', 'mt', 'ht', 'dt', 'gm', 'tm', 'nm', 'pt', 'st',
        'lt', 'gt', 'dn', 'cn', 'tn', 'bn', 'pn', 'mn', 'hn', 'gn', 'fn', 'rn',
        'cch', 'kch', 'thc', 'phc', 'nht', 'tht', 'sht', 'ght', 'dht', 'bht',
        'cc', 'dc', 'tc', 'nc', 'pc', 'gc', 'fc', 'bc', 'hc', 'lc', 'rc', 'sc',
        'tng', 'dng', 'bng', 'png', 'mng', 'lng', 'rng', 'sng', 'hng', 'gng',
        'cp', 'tp', 'dp', 'bp', 'hp', 'lp', 'rp', 'sp', 'mp', 'np', 'gp', 'fp',
        'cm', 'tm', 'dm', 'bm', 'hm', 'lm', 'rm', 'sm', 'nm', 'gm', 'fm', 'pm',
        # C√°c t·ª´ vi·∫øt t·∫Øt b·ªï sung
        'mmt', 'mmm', 'trt', 'sst', 'bbt', 'lll', 'kkk', 'rrr', 'nnn', 'ttt',
        'l', 'k', 'n', 'r', 's', 'b', 'g', 'f', 'h', 'j', 'p', 'q', 'v', 'w', 'x', 'z',
        # T·ª´ vi·∫øt t·∫Øt c·ªßa "kh√°i ni·ªám", "ki·ªÉm so√°t", "ch·∫•t l∆∞·ª£ng"
        'kni', 'ksot', 'clung', 'khai', 'niem', 'kiem', 'soat', 'chat', 'luong',
        'cqun', 'ccht', 'clng', 'qll', 'qlt', 'clt', 'qnl', 'knl', 'ksl'
    }
    
    # Ki·ªÉm tra t·ª´ vi·∫øt t·∫Øt ti·∫øng Vi·ªát
    if clean_word.lower() in vietnamese_abbreviations:
        return True
    
    # Ki·ªÉm tra c√°c k√Ω t·ª± ƒë∆°n l·∫ª c√≥ th·ªÉ l√† vi·∫øt t·∫Øt ti·∫øng Vi·ªát
    if len(clean_word) == 1:
        # Nh·ªØng k√Ω t·ª± ƒë∆°n l·∫ª th∆∞·ªùng l√† vi·∫øt t·∫Øt ti·∫øng Vi·ªát (tr·ª´ A, I)
        single_chars_to_remove = set('bcdfghjklmnpqrstvwxyz')
        if clean_word.lower() in single_chars_to_remove:
            return True
    
    # Ki·ªÉm tra c√°c pattern ti·∫øng Vi·ªát kh√¥ng d·∫•u
    # Pattern 1: t·ª´ ch·ªâ c√≥ ph·ª• √¢m (kh√¥ng c√≥ nguy√™n √¢m a,e,i,o,u)
    if len(clean_word) >= 2 and len(clean_word) <= 4:
        vowels = set('aeiouAEIOU')
        if not any(char in vowels for char in clean_word):
            # Ki·ªÉm tra xem c√≥ ph·∫£i l√† t·ª´ ti·∫øng Anh hay kh√¥ng
            common_english_consonant_words = {'by', 'my', 'try', 'fly', 'sky', 'dry', 'cry', 'fry', 'why'}
            if clean_word.lower() not in common_english_consonant_words:
                return True
    
    return False

def should_keep_paragraph(text):
    """Quy·∫øt ƒë·ªãnh c√≥ n√™n gi·ªØ l·∫°i paragraph kh√¥ng"""
    if not text or not text.strip():
        return False
    
    # N·∫øu c√≥ k√Ω t·ª± Nh·∫≠t th√¨ gi·ªØ l·∫°i
    if any(is_japanese_char(char) for char in text):
        return True
    
    # ƒê·∫øm s·ªë t·ª´ ti·∫øng Vi·ªát trong ƒëo·∫°n text
    words = text.split()
    vietnamese_word_count = 0
    total_words = 0
    
    for word in words:
        # B·ªè qua d·∫•u c√¢u khi ƒë·∫øm t·ª´
        clean_word = word.strip('.,!?;:()[]{}"-\'')
        if clean_word and clean_word.isalpha():
            total_words += 1
            if should_remove_vietnamese_word(word):
                vietnamese_word_count += 1
    
    # N·∫øu kh√¥ng c√≥ t·ª´ n√†o th√¨ gi·ªØ l·∫°i
    if total_words == 0:
        return True
    
    # N·∫øu c√≥ h∆°n 30% t·ª´ ti·∫øng Vi·ªát th√¨ x√≥a c·∫£ ƒëo·∫°n
    vietnamese_ratio = vietnamese_word_count / total_words
    if vietnamese_ratio > 0.3:
        return False
    
    # N·∫øu ch·ªß y·∫øu l√† ti·∫øng Anh th√¨ gi·ªØ l·∫°i
    alpha_chars = [char for char in text if char.isalpha()]
    if alpha_chars:
        english_count = sum(1 for char in alpha_chars if is_english_char(char))
        if english_count / len(alpha_chars) > 0.6:
            return True
    
    # M·∫∑c ƒë·ªãnh gi·ªØ l·∫°i n·∫øu kh√¥ng c√≥ nhi·ªÅu t·ª´ ti·∫øng Vi·ªát
    return True

def clean_text(text):
    """L√†m s·∫°ch text, x√≥a c√°c t·ª´ ti·∫øng Vi·ªát"""
    if not text:
        return ""
    
    # T√°ch th√†nh c√°c t·ª´
    words = text.split()
    clean_words = []
    
    for word in words:
        # N·∫øu t·ª´ c√≥ k√Ω t·ª± Nh·∫≠t th√¨ gi·ªØ nguy√™n
        if any(is_japanese_char(char) for char in word):
            clean_words.append(word)
        # N·∫øu t·ª´ l√† ti·∫øng Vi·ªát (c√≥ d·∫•u ho·∫∑c kh√¥ng d·∫•u) th√¨ b·ªè qua ho√†n to√†n
        elif should_remove_vietnamese_word(word):
            continue  # B·ªè qua t·ª´ n√†y ho√†n to√†n
        # N·∫øu t·ª´ ch·ªß y·∫øu l√† ti·∫øng Anh ho·∫∑c k√Ω t·ª± kh√°c th√¨ gi·ªØ nguy√™n
        else:
            clean_words.append(word)
    
    return ' '.join(clean_words)

def clean_text_preserve_format(text):
    """L√†m s·∫°ch text nh∆∞ng gi·ªØ nguy√™n v·ªã tr√≠ ƒë·ªÉ b·∫£o t·ªìn format"""
    if not text:
        return ""
    
    # T√°ch th√†nh c√°c t·ª´ nh∆∞ng gi·ªØ nguy√™n kho·∫£ng tr·∫Øng
    words = text.split(' ')
    clean_words = []
    
    for word in words:
        if not word:  # Kho·∫£ng tr·∫Øng tr·ªëng
            clean_words.append(word)
            continue
            
        # N·∫øu t·ª´ c√≥ k√Ω t·ª± Nh·∫≠t th√¨ gi·ªØ nguy√™n
        if any(is_japanese_char(char) for char in word):
            clean_words.append(word)
        # N·∫øu t·ª´ l√† ti·∫øng Vi·ªát th√¨ B·ªé QUA HO√ÄN TO√ÄN (kh√¥ng th√™m g√¨ c·∫£)
        elif should_remove_vietnamese_word(word):
            continue  # B·ªè qua t·ª´ n√†y ho√†n to√†n, kh√¥ng th√™m v√†o clean_words
        # N·∫øu t·ª´ ch·ªß y·∫øu l√† ti·∫øng Anh ho·∫∑c k√Ω t·ª± kh√°c th√¨ gi·ªØ nguy√™n
        else:
            clean_words.append(word)
    
    # N·ªëi l·∫°i v√† lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
    result = ' '.join(clean_words)
    # Lo·∫°i b·ªè nhi·ªÅu kho·∫£ng tr·∫Øng li√™n ti·∫øp
    result = re.sub(r'\s+', ' ', result)
    return result.strip()

def clean_run_preserve_format(run):
    """L√†m s·∫°ch m·ªôt run trong Word document v√† gi·ªØ nguy√™n format"""
    if not run.text:
        return False
    
    original_text = run.text
    cleaned_text = clean_text_preserve_format(original_text)
    
    # N·∫øu text b·ªã thay ƒë·ªïi th√¨ c·∫≠p nh·∫≠t
    if cleaned_text != original_text:
        run.text = cleaned_text
        return True
    
    return False

def remove_vietnamese_from_docx(input_file, output_file):
    """X√≥a ti·∫øng Vi·ªát kh·ªèi file Word v√† gi·ªØ nguy√™n format"""
    print(f"üìñ ƒêang x·ª≠ l√Ω file: {input_file}")
    
    try:
        # M·ªü file Word
        doc = Document(input_file)
        
        # Th·ªëng k√™
        total_paragraphs = len(doc.paragraphs)
        removed_paragraphs = 0
        processed_paragraphs = 0
        cleaned_paragraphs = 0
        cleaned_runs = 0
        
        print(f"üìä T·ªïng s·ªë paragraph: {total_paragraphs}")
        
        # X·ª≠ l√Ω t·ª´ng paragraph
        paragraphs_to_remove = []
        
        for i, paragraph in enumerate(doc.paragraphs):
            original_text = paragraph.text
            
            if not original_text.strip():
                continue
                
            processed_paragraphs += 1
            
            # Ki·ªÉm tra xem c√≥ n√™n gi·ªØ l·∫°i paragraph kh√¥ng
            if should_keep_paragraph(original_text):
                # L√†m s·∫°ch to√†n b·ªô text c·ªßa paragraph tr∆∞·ªõc
                cleaned_full_text = clean_text_preserve_format(original_text)
                
                # N·∫øu text ƒë√£ thay ƒë·ªïi, c·∫≠p nh·∫≠t l·∫°i to√†n b·ªô paragraph
                if cleaned_full_text != original_text:
                    # X√≥a text kh·ªèi t·∫•t c·∫£ runs hi·ªán t·∫°i v√† ch·ªâ gi·ªØ l·∫°i run ƒë·∫ßu ti√™n
                    if paragraph.runs:
                        # Gi·ªØ run ƒë·∫ßu ti√™n v√† x√≥a text c·ªßa c√°c run kh√°c
                        first_run = paragraph.runs[0]
                        first_run.text = cleaned_full_text
                        
                        # X√≥a text c·ªßa c√°c run c√≤n l·∫°i
                        for run in paragraph.runs[1:]:
                            run.text = ""
                    else:
                        # N·∫øu kh√¥ng c√≥ run n√†o, t·∫°o run m·ªõi
                        new_run = paragraph.add_run()
                        new_run.text = cleaned_full_text
                    
                    cleaned_paragraphs += 1
                    cleaned_runs += 1
                    print(f"‚úÖ Paragraph {i+1}: ƒê√£ l√†m s·∫°ch to√†n b·ªô")
                    print(f"   Tr∆∞·ªõc: {original_text[:100]}...")
                    print(f"   Sau:  {cleaned_full_text[:100]}...")
                
                # Ki·ªÉm tra xem paragraph c√≤n n·ªôi dung kh√¥ng sau khi l√†m s·∫°ch
                if not cleaned_full_text.strip():
                    paragraphs_to_remove.append(paragraph)
                    removed_paragraphs += 1
                    print(f"‚ùå Paragraph {i+1}: X√≥a (kh√¥ng c√≤n n·ªôi dung sau khi l√†m s·∫°ch)")
            else:
                # ƒê√°nh d·∫•u ƒë·ªÉ x√≥a to√†n b·ªô paragraph
                paragraphs_to_remove.append(paragraph)
                removed_paragraphs += 1
                print(f"‚ùå Paragraph {i+1}: X√≥a (c√≥ nhi·ªÅu t·ª´ ti·∫øng Vi·ªát)")
                print(f"   N·ªôi dung: {original_text[:100]}...")
        
        # X√≥a c√°c paragraph ƒë√£ ƒë√°nh d·∫•u
        for paragraph in paragraphs_to_remove:
            p = paragraph._element
            p.getparent().remove(p)
        
        # L∆∞u file k·∫øt qu·∫£
        doc.save(output_file)
        
        print(f"\nüéâ Ho√†n th√†nh!")
        print(f"üìä Th·ªëng k√™:")
        print(f"   - T·ªïng s·ªë paragraph: {total_paragraphs}")
        print(f"   - ƒê√£ x·ª≠ l√Ω: {processed_paragraphs}")
        print(f"   - ƒê√£ l√†m s·∫°ch: {cleaned_paragraphs}")
        print(f"   - ƒê√£ l√†m s·∫°ch runs: {cleaned_runs}")
        print(f"   - ƒê√£ x√≥a: {removed_paragraphs}")
        print(f"   - C√≤n l·∫°i: {total_paragraphs - removed_paragraphs}")
        print(f"üíæ File k·∫øt qu·∫£: {output_file}")
        
    except Exception as e:
        print(f"‚ùå L·ªói: {str(e)}")
        return False
    
    return True

def main():
    """H√†m ch√≠nh"""
    input_file = "kienthucchungfinal.docx"
    output_file = "kienthucchungfinal_cleaned_v2.docx"
    
    # Ki·ªÉm tra file ƒë·∫ßu v√†o
    if not os.path.exists(input_file):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {input_file}")
        return
    
    print("üöÄ B·∫ÆT ƒê·∫¶U X√ìA TI·∫æNG VI·ªÜT KH·ªéI FILE WORD")
    print("=" * 50)
    
    # X·ª≠ l√Ω file
    success = remove_vietnamese_from_docx(input_file, output_file)
    
    if success:
        print(f"\n‚úÖ Th√†nh c√¥ng! File k·∫øt qu·∫£: {output_file}")
    else:
        print(f"\n‚ùå Th·∫•t b·∫°i!")

if __name__ == "__main__":
    main()
