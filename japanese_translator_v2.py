import google.generativeai as genai
import json
import re
from docx import Document
from docx.shared import RGBColor
import time
import os
from typing import List, Dict, Optional

# Regex patterns for Japanese text detection
JAPANESE_PATTERN = re.compile(r'[\u3040-\u309f\u30a0-\u30ff\u4e00-\u9fff]+')

class JapaneseToVietnameseTranslator:
    def __init__(self, api_key: str):
        """Initialize translator with Gemini API key"""
        if not api_key or api_key == "your_gemini_api_key_here":
            raise ValueError("Please provide a valid Gemini API key")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-1.5-flash')  # S·ª≠ d·ª•ng model m·ªõi h∆°n
        self.translation_cache = {}
        self.request_count = 0
        self.daily_request_count = 0  # Theo d√µi requests h√†ng ng√†y
        self.max_requests_per_minute = 12  # Gi·ªõi h·∫°n API calls (free tier: 15/ph√∫t, ƒë·ªÉ d∆∞ 3)
        self.max_requests_per_day = 45    # Gi·ªõi h·∫°n h√†ng ng√†y (free tier: 50/ng√†y, ƒë·ªÉ d∆∞ 5)
        self.start_time = time.time()  # Theo d√µi th·ªùi gian b·∫Øt ƒë·∫ßu
        self.daily_start_time = time.time()  # Theo d√µi th·ªùi gian b·∫Øt ƒë·∫ßu ng√†y
        
    def has_japanese(self, text: str) -> bool:
        """Ki·ªÉm tra xem text c√≥ ch·ª©a k√Ω t·ª± ti·∫øng Nh·∫≠t kh√¥ng"""
        if not text:
            return False
        return bool(JAPANESE_PATTERN.search(text))
    
    def clean_japanese_text(self, text: str) -> str:
        """L√†m s·∫°ch text ti·∫øng Nh·∫≠t"""
        # Lo·∫°i b·ªè whitespace th·ª´a
        text = re.sub(r'\s+', ' ', text).strip()
        
        # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát kh√¥ng c·∫ßn thi·∫øt
        text = re.sub(r'[^\u3040-\u309f\u30a0-\u30ff\u4e00-\u9fff\s.,!?()ÔºàÔºâ„Äå„Äç„Äé„Äè„ÄÅ„ÄÇÔºÅÔºü]', '', text)
        
        return text
    
    def split_long_text(self, text: str, max_length: int = 500) -> List[str]:
        """Chia text d√†i th√†nh c√°c ƒëo·∫°n ng·∫Øn h∆°n ƒë·ªÉ d·ªãch"""
        if len(text) <= max_length:
            return [text]
        
        # Chia theo c√¢u tr∆∞·ªõc
        sentences = re.split(r'[„ÄÇÔºÅÔºü\n]', text)
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            if len(current_chunk + sentence) <= max_length:
                current_chunk += sentence + "„ÄÇ"
            else:
                if current_chunk:
                    chunks.append(current_chunk.rstrip("„ÄÇ"))
                current_chunk = sentence + "„ÄÇ"
        
        if current_chunk:
            chunks.append(current_chunk.rstrip("„ÄÇ"))
        
        return chunks
    
    def translate_text(self, japanese_text: str) -> Optional[str]:
        """D·ªãch text ti·∫øng Nh·∫≠t sang ti·∫øng Vi·ªát b·∫±ng Gemini API"""
        if not japanese_text or not self.has_japanese(japanese_text):
            return None
        
        # L√†m s·∫°ch text
        cleaned_text = self.clean_japanese_text(japanese_text)
        if not cleaned_text:
            return None
        
        # Ki·ªÉm tra cache tr∆∞·ªõc
        cache_key = cleaned_text.strip()
        if cache_key in self.translation_cache:
            print(f"‚úì Cache hit: {cache_key[:50]}...")
            return self.translation_cache[cache_key]
        
        # Ki·ªÉm tra rate limit v·ªõi th·ªùi gian th·ª±c t·∫ø
        current_time = time.time()
        elapsed_time = current_time - self.start_time
        
        # Reset counter m·ªói ph√∫t
        if elapsed_time >= 60:
            self.request_count = 0
            self.start_time = current_time
            elapsed_time = 0
        
        # Ki·ªÉm tra daily quota TR∆Ø·ªöC
        if self.daily_request_count >= self.max_requests_per_day:
            print(f"üö´ DAILY QUOTA EXCEEDED! ({self.daily_request_count}/{self.max_requests_per_day})")
            print("   Free tier ch·ªâ cho ph√©p 50 requests/ng√†y")
            print("   H√£y th·ª≠ l·∫°i v√†o ng√†y mai ho·∫∑c upgrade plan")
            return f"[Daily quota exceeded - {self.daily_request_count}/{self.max_requests_per_day}]"
        
        # Ki·ªÉm tra rate limit per minute
        if self.request_count >= self.max_requests_per_minute:
            wait_time = 60 - elapsed_time + 5  # Th√™m 5 gi√¢y buffer
            print(f"‚è≥ Rate limit reached ({self.request_count}/{self.max_requests_per_minute}), waiting {wait_time:.1f} seconds...")
            time.sleep(wait_time)
            self.request_count = 0
            self.start_time = time.time()
        
        try:
            # Chia text d√†i th√†nh chunks nh·ªè h∆°n
            chunks = self.split_long_text(cleaned_text)
            translations = []
            
            for chunk in chunks:
                prompt = f"""
D·ªãch ƒëo·∫°n vƒÉn ti·∫øng Nh·∫≠t sau sang ti·∫øng Vi·ªát m·ªôt c√°ch t·ª± nhi√™n v√† ch√≠nh x√°c:

Y√™u c·∫ßu:
- D·ªãch ch√≠nh x√°c nghƒ©a v√† ng·ªØ c·∫£nh
- S·ª≠ d·ª•ng t·ª´ ng·ªØ ti·∫øng Vi·ªát t·ª± nhi√™n, kh√¥ng m√°y m√≥c
- Gi·ªØ nguy√™n c·∫•u tr√∫c c√¢u h·ª£p l√Ω
- Kh√¥ng th√™m gi·∫£i th√≠ch hay ch√∫ th√≠ch
- Ch·ªâ tr·∫£ v·ªÅ b·∫£n d·ªãch ti·∫øng Vi·ªát

VƒÉn b·∫£n ti·∫øng Nh·∫≠t:
{chunk}

B·∫£n d·ªãch ti·∫øng Vi·ªát:"""

                response = self.model.generate_content(
                    prompt,
                    generation_config={
                        'temperature': 0.3,  # Gi·∫£m t√≠nh ng·∫´u nhi√™n
                        'max_output_tokens': 2048,
                    }
                )
                
                if response.text:
                    translation = response.text.strip()
                    # Lo·∫°i b·ªè c√°c prefix kh√¥ng mong mu·ªën
                    translation = re.sub(r'^(B·∫£n d·ªãch ti·∫øng Vi·ªát:|D·ªãch:|Translation:)\s*', '', translation, flags=re.IGNORECASE)
                    translations.append(translation)
                
                self.request_count += 1
                self.daily_request_count += 1  # C·∫≠p nh·∫≠t daily counter
                
                # Delay gi·ªØa c√°c request ƒë·ªÉ tr√°nh rate limit (tƒÉng delay)
                time.sleep(1.0)  # TƒÉng t·ª´ 0.5 l√™n 1.0 gi√¢y
            
            # K·∫øt h·ª£p c√°c translations
            final_translation = " ".join(translations)
            
            # L∆∞u v√†o cache
            self.translation_cache[cache_key] = final_translation
            
            print(f"‚úì Translated: {cleaned_text[:50]}... ‚Üí {final_translation[:50]}...")
            return final_translation
            
        except Exception as e:
            error_msg = str(e)
            
            # Ki·ªÉm tra n·∫øu l√† daily quota error
            if "429" in error_msg and "FreeTier" in error_msg and "PerDay" in error_msg:
                print(f"üö´ DAILY QUOTA EXCEEDED! API ƒë√£ v∆∞·ª£t qu√° 50 requests/ng√†y")
                print("   Gi·∫£i ph√°p:")
                print("   1. ƒê·ª£i ƒë·∫øn ng√†y mai ƒë·ªÉ reset quota")
                print("   2. Upgrade l√™n paid plan t·∫°i: https://aistudio.google.com/app/pricing")
                print("   3. S·ª≠ d·ª•ng cache cho c√°c text ƒë√£ d·ªãch")
                return f"[Daily quota exceeded - H√£y th·ª≠ l·∫°i v√†o ng√†y mai]"
            
            # C√°c l·ªói kh√°c
            error_msg = f"[L·ªói d·ªãch: {str(e)}]"
            print(f"‚úó Error translating '{cleaned_text[:50]}...': {e}")
            return error_msg
    
    def add_translation_to_paragraph(self, paragraph, vietnamese_text: str):
        """Th√™m b·∫£n d·ªãch ti·∫øng Vi·ªát v√†o paragraph"""
        # Th√™m xu·ªëng d√≤ng
        paragraph.add_run().add_break()
        
        # Th√™m text ti·∫øng Vi·ªát v·ªõi format ƒë·∫∑c bi·ªát
        vn_run = paragraph.add_run(f"üáªüá≥ {vietnamese_text}")
        
        # ƒê·ªãnh d·∫°ng cho text ti·∫øng Vi·ªát
        vn_run.font.italic = True
        vn_run.font.color.rgb = RGBColor(0, 100, 0)  # M√†u xanh l√° ƒë·∫≠m
        vn_run.font.size = vn_run.font.size  # Gi·ªØ nguy√™n size
    
    def process_paragraph(self, paragraph) -> bool:
        """X·ª≠ l√Ω m·ªôt paragraph v√† th√™m b·∫£n d·ªãch ti·∫øng Vi·ªát"""
        original_text = paragraph.text.strip()
        
        if not original_text or not self.has_japanese(original_text):
            return False
        
        # D·ªãch text
        vietnamese_translation = self.translate_text(original_text)
        
        if not vietnamese_translation or vietnamese_translation.startswith("[L·ªói d·ªãch"):
            return False
        
        # Th√™m b·∫£n d·ªãch v√†o paragraph
        self.add_translation_to_paragraph(paragraph, vietnamese_translation)
        
        return True
    
    def process_table_cell(self, cell) -> int:
        """X·ª≠ l√Ω c√°c paragraph trong table cell"""
        translated_count = 0
        
        for paragraph in cell.paragraphs:
            if self.process_paragraph(paragraph):
                translated_count += 1
        
        return translated_count
    
    def process_word_document(self, input_path: str, output_path: str):
        """X·ª≠ l√Ω file Word v√† th√™m b·∫£n d·ªãch ti·∫øng Vi·ªát"""
        print(f"üîÑ ƒêang x·ª≠ l√Ω t√†i li·ªáu: {input_path}")
        start_time = time.time()
        
        try:
            doc = Document(input_path)
            
            # Th·ªëng k√™
            stats = {
                'total_paragraphs': 0,
                'japanese_paragraphs': 0,
                'translated_paragraphs': 0,
                'tables_processed': 0,
                'cells_processed': 0
            }
            
            print("üìÑ ƒêang x·ª≠ l√Ω paragraphs ch√≠nh...")
            
            # X·ª≠ l√Ω paragraphs ch√≠nh
            for i, paragraph in enumerate(doc.paragraphs):
                stats['total_paragraphs'] += 1
                
                if self.has_japanese(paragraph.text):
                    stats['japanese_paragraphs'] += 1
                    
                    if self.process_paragraph(paragraph):
                        stats['translated_paragraphs'] += 1
                    
                    # Hi·ªÉn th·ªã ti·∫øn tr√¨nh
                    if stats['japanese_paragraphs'] % 10 == 0:
                        elapsed = time.time() - start_time
                        print(f"  üìù ƒê√£ x·ª≠ l√Ω {stats['japanese_paragraphs']} ƒëo·∫°n ti·∫øng Nh·∫≠t - {elapsed:.1f}s")
            
            print("üìä ƒêang x·ª≠ l√Ω tables...")
            
            # X·ª≠ l√Ω tables
            for table_idx, table in enumerate(doc.tables):
                stats['tables_processed'] += 1
                
                for row in table.rows:
                    for cell in row.cells:
                        stats['cells_processed'] += 1
                        cell_translated = self.process_table_cell(cell)
                        stats['translated_paragraphs'] += cell_translated
                
                # Hi·ªÉn th·ªã ti·∫øn tr√¨nh table
                if (table_idx + 1) % 5 == 0:
                    elapsed = time.time() - start_time
                    print(f"  üìã ƒê√£ x·ª≠ l√Ω {table_idx + 1} tables - {elapsed:.1f}s")
            
            # L∆∞u t√†i li·ªáu
            print("üíæ ƒêang l∆∞u t√†i li·ªáu...")
            save_start = time.time()
            doc.save(output_path)
            save_time = time.time() - save_start
            
            # L∆∞u cache
            cache_file = output_path.replace('.docx', '_translation_cache.json')
            self.save_cache(cache_file)
            
            total_time = time.time() - start_time
            
            # In b√°o c√°o k·∫øt qu·∫£
            self.print_results(output_path, stats, total_time, save_time, cache_file)
            
        except Exception as e:
            print(f"‚ùå L·ªói x·ª≠ l√Ω t√†i li·ªáu: {e}")
            import traceback
            traceback.print_exc()
    
    def save_cache(self, cache_file: str):
        """L∆∞u cache d·ªãch thu·∫≠t"""
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.translation_cache, f, ensure_ascii=False, indent=2)
            print(f"üíæ ƒê√£ l∆∞u {len(self.translation_cache)} b·∫£n d·ªãch v√†o cache")
        except Exception as e:
            print(f"‚ùå L·ªói l∆∞u cache: {e}")
    
    def load_cache(self, cache_file: str):
        """T·∫£i cache d·ªãch thu·∫≠t c√≥ s·∫µn"""
        try:
            if os.path.exists(cache_file):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    self.translation_cache = json.load(f)
                print(f"üì• ƒê√£ t·∫£i {len(self.translation_cache)} b·∫£n d·ªãch t·ª´ cache")
            else:
                print("üìù Kh√¥ng t√¨m th·∫•y cache, b·∫Øt ƒë·∫ßu t·ª´ ƒë·∫ßu")
        except Exception as e:
            print(f"‚ùå L·ªói t·∫£i cache: {e}")
    
    def print_results(self, output_path: str, stats: Dict, total_time: float, save_time: float, cache_file: str):
        """In b√°o c√°o k·∫øt qu·∫£"""
        print("\n" + "="*60)
        print("üéâ K·∫æT QU·∫¢ D·ªäCH THU·∫¨T")
        print("="*60)
        print(f"üìÅ File ƒë·∫ßu ra: {output_path}")
        print(f"üìä T·ªïng paragraphs: {stats['total_paragraphs']}")
        print(f"üáØüáµ Paragraphs ti·∫øng Nh·∫≠t: {stats['japanese_paragraphs']}")
        print(f"üáªüá≥ Paragraphs ƒë√£ d·ªãch: {stats['translated_paragraphs']}")
        print(f"üìã Tables ƒë√£ x·ª≠ l√Ω: {stats['tables_processed']}")
        print(f"üìÑ Cells ƒë√£ x·ª≠ l√Ω: {stats['cells_processed']}")
        print(f"üíæ B·∫£n d·ªãch trong cache: {len(self.translation_cache)}")
        print(f"‚è±Ô∏è  Th·ªùi gian x·ª≠ l√Ω: {total_time:.2f} gi√¢y")
        print(f"üíæ Th·ªùi gian l∆∞u: {save_time:.2f} gi√¢y")
        print(f"üìÇ Cache file: {cache_file}")
        
        if stats['japanese_paragraphs'] > 0:
            success_rate = (stats['translated_paragraphs'] / stats['japanese_paragraphs']) * 100
            print(f"‚úÖ T·ª∑ l·ªá th√†nh c√¥ng: {success_rate:.1f}%")
        
        print("="*60)
    
    def batch_translate_paragraphs(self, paragraphs_data: List[tuple], batch_size: int = 5) -> Dict[str, str]:
        """D·ªãch nhi·ªÅu ƒëo·∫°n vƒÉn c√πng l√∫c ƒë·ªÉ ti·∫øt ki·ªám API calls"""
        batch_results = {}
        
        # T·∫°o batches t·ª´ paragraphs ch∆∞a c√≥ trong cache
        batches = []
        current_batch = []
        
        for para_id, text in paragraphs_data:
            cleaned_text = self.clean_japanese_text(text)
            if cleaned_text and cleaned_text not in self.translation_cache:
                current_batch.append((para_id, cleaned_text))
                
                if len(current_batch) >= batch_size:
                    batches.append(current_batch)
                    current_batch = []
        
        if current_batch:
            batches.append(current_batch)
        
        # X·ª≠ l√Ω t·ª´ng batch
        for batch_idx, batch in enumerate(batches):
            print(f"üîÑ Processing batch {batch_idx + 1}/{len(batches)} ({len(batch)} items)")
            
            # T·∫°o combined prompt cho c·∫£ batch
            combined_text = "\n---\n".join([f"[{para_id}] {text}" for para_id, text in batch])
            
            prompt = f"""
D·ªãch c√°c ƒëo·∫°n vƒÉn ti·∫øng Nh·∫≠t sau sang ti·∫øng Vi·ªát. M·ªói ƒëo·∫°n ƒë∆∞·ª£c ƒë√°nh s·ªë [ID].
Tr·∫£ v·ªÅ k·∫øt qu·∫£ theo ƒë·ªãnh d·∫°ng: [ID] B·∫£n d·ªãch ti·∫øng Vi·ªát

Y√™u c·∫ßu:
- D·ªãch ch√≠nh x√°c nghƒ©a v√† ng·ªØ c·∫£nh
- S·ª≠ d·ª•ng t·ª´ ng·ªØ ti·∫øng Vi·ªát t·ª± nhi√™n
- Gi·ªØ ƒë√∫ng ƒë·ªãnh d·∫°ng [ID] tr∆∞·ªõc m·ªói b·∫£n d·ªãch

VƒÉn b·∫£n ti·∫øng Nh·∫≠t:
{combined_text}

B·∫£n d·ªãch ti·∫øng Vi·ªát:"""

            try:
                # Ki·ªÉm tra rate limit tr∆∞·ªõc khi g·ªçi API
                current_time = time.time()
                elapsed_time = current_time - self.start_time
                
                if elapsed_time >= 60:
                    self.request_count = 0
                    self.start_time = current_time
                elif self.request_count >= self.max_requests_per_minute:
                    wait_time = 60 - elapsed_time + 5
                    print(f"‚è≥ Waiting {wait_time:.1f}s for rate limit...")
                    time.sleep(wait_time)
                    self.request_count = 0
                    self.start_time = time.time()
                
                response = self.model.generate_content(
                    prompt,
                    generation_config={
                        'temperature': 0.3,
                        'max_output_tokens': 2048,
                    }
                )
                
                self.request_count += 1
                
                if response.text:
                    # Parse k·∫øt qu·∫£ batch
                    lines = response.text.strip().split('\n')
                    for line in lines:
                        line = line.strip()
                        if line.startswith('[') and ']' in line:
                            try:
                                end_bracket = line.index(']')
                                para_id = line[1:end_bracket]
                                translation = line[end_bracket + 1:].strip()
                                
                                # T√¨m text g·ªëc t∆∞∆°ng ·ª©ng
                                for orig_id, orig_text in batch:
                                    if orig_id == para_id:
                                        self.translation_cache[orig_text] = translation
                                        batch_results[orig_text] = translation
                                        break
                            except (ValueError, IndexError):
                                continue
                
                # Delay gi·ªØa c√°c batch
                time.sleep(2.0)
                
            except Exception as e:
                print(f"‚ùå Error in batch {batch_idx + 1}: {e}")
                # Fallback: d·ªãch t·ª´ng ƒëo·∫°n ri√™ng
                for para_id, text in batch:
                    try:
                        translation = self.translate_text(text)
                        if translation:
                            batch_results[text] = translation
                    except Exception as fallback_error:
                        print(f"‚ùå Fallback error for {para_id}: {fallback_error}")
        
        return batch_results

def main():
    """H√†m ch√≠nh"""
    # Import config t·ª´ file ri√™ng
    try:
        from config import get_config, print_config
        CONFIG = get_config()
        if CONFIG is None:
            return
        print_config()
    except ImportError:
        print("‚ùå Kh√¥ng t√¨m th·∫•y file config.py!")
        print("   Vui l√≤ng t·∫°o file config.py v·ªõi API key")
        return
    
    print("üåü JAPANESE TO VIETNAMESE TRANSLATOR V2")
    print("="*50)
    print(f"üì• Input: {CONFIG['input_file']}")
    print(f"üì§ Output: {CONFIG['output_file']}")
    print()
    
    # Ki·ªÉm tra file input
    if not os.path.exists(CONFIG['input_file']):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file input: {CONFIG['input_file']}")
        return
    
    try:
        # Kh·ªüi t·∫°o translator
        print("üîß ƒêang kh·ªüi t·∫°o translator...")
        translator = JapaneseToVietnameseTranslator(CONFIG['api_key'])
        
        # T·∫£i cache c√≥ s·∫µn
        translator.load_cache(CONFIG['cache_file'])
        
        # X·ª≠ l√Ω t√†i li·ªáu
        translator.process_word_document(CONFIG['input_file'], CONFIG['output_file'])
        
        print("\nüéä D·ªäCH THU·∫¨T HO√ÄN TH√ÄNH!")
        
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
